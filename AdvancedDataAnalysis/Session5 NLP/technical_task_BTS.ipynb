{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JMp8K0iJPr3"
   },
   "source": [
    "# Technical task - BBC data set\n",
    "\n",
    "We are going to build a classifier that categorize BBC articles into 5 different topics/classes: Politics, business, sport, entertainment and techology. We will use 2225 documents from the BBC news website to train and test an algorithm.\n",
    "\n",
    "The data can be downloaded from this website: http://mlg.ucd.ie/datasets/bbc.html We are going to use the Dataset: BBC in raw format.\n",
    "\n",
    "Firstly we will prepare the data to be ingested by the ML algorithm, afterwords we will train the models and finally we will evaluate the performance.\n",
    "\n",
    "We have also explored the use of LDA for the extraction of natural topics in this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TxXfdWMAJPr4"
   },
   "source": [
    "# 1. Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-9-5kSmAJkkR"
   },
   "outputs": [],
   "source": [
    "#If not installed uncomment\n",
    "#!pip install spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u6JKcaCFLwe0",
    "outputId": "b2670955-26eb-401d-b68c-318d761ee1b1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.0.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.0.0/en_core_web_sm-3.0.0-py3-none-any.whl (13.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.7 MB 13.2 MB/s eta 0:00:01   |████████████▎                   | 5.3 MB 7.2 MB/s eta 0:00:02     |████████████████                | 6.9 MB 7.2 MB/s eta 0:00:01     |███████████████████▉            | 8.5 MB 7.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.1.0,>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.7.4)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.21.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (20.9)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.1)\n",
      "Requirement already satisfied: typer<0.4.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.3.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.3 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (8.0.6)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.61.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.8.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.1)\n",
      "Requirement already satisfied: pydantic<1.8.0,>=1.7.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.7.4)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.3 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.4)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /opt/conda/lib/python3.9/site-packages (from spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (0.5.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<4.0.0,>=2.2.0 in /opt/conda/lib/python3.9/site-packages (from pathy>=0.3.5->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (3.0.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2021.5.30)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (1.26.5)\n",
      "Requirement already satisfied: click<7.2.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.4.0,>=0.3.0->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.1.0,>=3.0.0->en-core-web-sm==3.0.0) (2.0.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRjhVObcO5cR",
    "outputId": "c25b9fe1-caff-4eeb-89e2-d72c2aab64c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('bbc-fulltext.zip', 'r') as zipObj: \n",
    "   zipObj.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oxAYZiQwJPr5"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import os\n",
    "import pandas as pd\n",
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "NR_9Ionoez2T",
    "outputId": "a83f39a8-5ac1-4c9b-d3e3-831a14474e2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is first sentence.\n",
      "Second sentence.\n",
      "Third sentence.\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "text = u\"This is first sentence. Second sentence. Third sentence.\"\n",
    "text_sentences = nlp(text)\n",
    "for sentence in text_sentences.sents:\n",
    "    print(sentence.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfH-MtFtjb-O",
    "outputId": "01acea7a-0ed3-4e17-b723-1ce22116c09d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(u'I', u'-PRON-', True, u'PRON')\n",
      "(u'am', u'be', True, u'VERB')\n",
      "(u'Clara', u'Clara', False, u'PROPN')\n",
      "(u'and', u'and', True, u'CCONJ')\n",
      "(u'this', u'this', True, u'DET')\n",
      "(u'is', u'be', True, u'VERB')\n",
      "(u'the', u'the', True, u'DET')\n",
      "(u'NLP', u'NLP', False, u'PROPN')\n",
      "(u'class', u'class', False, u'NOUN')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "doc = nlp(u'I am Clara and this is the NLP class')\n",
    "for token in doc:\n",
    "     print(token.text, token.lemma_, token.is_stop, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "D-yB0bw_JPr7"
   },
   "outputs": [],
   "source": [
    "# function that loops through the directories that contain the files. Read them, extract the topic/class from the name of each folder\n",
    "# and returns a dataframe\n",
    "\n",
    "def extract_articles(path):\n",
    "#rootdir = \n",
    "    cat_article=[]\n",
    "    for subdir, dirs, files in os.walk(path):\n",
    "        print(subdir)\n",
    "        for file in files:\n",
    "            if '.txt' in file:      \n",
    "                category= subdir.split('/')[-1]\n",
    "                f=open(os.path.join(subdir, file),'r',encoding='utf-8',errors='ignore')\n",
    "                lines=f.readlines()\n",
    "                lines=' '.join(lines).replace('\\n','')\n",
    "                #list of lists: [category,article]\n",
    "                cat_article.append([category,lines])\n",
    "                f.close()\n",
    "    # we convert the list of lists [category, article] into a pandas dataframe            \n",
    "    data=pd.DataFrame(cat_article)\n",
    "    data.columns=['category','article']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "NiXpmkt_JPr8",
    "outputId": "906563cc-3937-4dcb-df6e-5a51a887473d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./bbc\n",
      "./bbc/business\n",
      "./bbc/entertainment\n",
      "./bbc/politics\n",
      "./bbc/sport\n",
      "./bbc/tech\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>Ad sales boost Time Warner profit  Quarterly p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>Dollar gains on Greenspan speech  The dollar h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>Yukos unit buyer faces loan claim  The owners ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>High fuel prices hit BA's profits  British Air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>Pernod takeover talk lifts Domecq  Shares in U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>business</td>\n",
       "      <td>Japan narrowly escapes recession  Japan's econ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>business</td>\n",
       "      <td>Jobs growth still slow in the US  The US creat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>business</td>\n",
       "      <td>India calls for fair trade rules  India, which...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>business</td>\n",
       "      <td>Ethiopia's crop production up 24%  Ethiopia pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>business</td>\n",
       "      <td>Court rejects $280bn tobacco case  A US govern...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                            article\n",
       "0  business  Ad sales boost Time Warner profit  Quarterly p...\n",
       "1  business  Dollar gains on Greenspan speech  The dollar h...\n",
       "2  business  Yukos unit buyer faces loan claim  The owners ...\n",
       "3  business  High fuel prices hit BA's profits  British Air...\n",
       "4  business  Pernod takeover talk lifts Domecq  Shares in U...\n",
       "5  business  Japan narrowly escapes recession  Japan's econ...\n",
       "6  business  Jobs growth still slow in the US  The US creat...\n",
       "7  business  India calls for fair trade rules  India, which...\n",
       "8  business  Ethiopia's crop production up 24%  Ethiopia pr...\n",
       "9  business  Court rejects $280bn tobacco case  A US govern..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data=extract_articles('/content/drive/MyDrive/BBC_articles/articles')\n",
    "data = extract_articles('./bbc')\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xiT3EQLJJPr-",
    "outputId": "70e04bdb-c701-424c-82bf-65cd0afbbd09"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "business         510\n",
       "entertainment    386\n",
       "politics         417\n",
       "sport            511\n",
       "tech             401\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('category').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "6Esv88UAJPr9"
   },
   "source": [
    "Number of articles per class. The number of samples per class is quite balanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XFqnJriJPr-"
   },
   "source": [
    "We are going to use a library for NLP called spacy. \n",
    "We need to convert the text into unicode format to be used by the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NiSB_9mvJPr_"
   },
   "outputs": [],
   "source": [
    "data['article'] = data['article'].apply(lambda x: x.decode('utf-8','ignore'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pyvNyTmZjBcy"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "_VBKiJ2cJPr_"
   },
   "outputs": [],
   "source": [
    "# we load english language to use spacy library and define functions that help us tokenize, \n",
    "# lemmatize the words of the articles and remove stop words.\n",
    "\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "def punct_space(token):\n",
    "    \"\"\"\n",
    "    helper function to eliminate tokens\n",
    "    that are pure punctuation or whitespace\n",
    "    \"\"\"\n",
    "    return token.is_punct or token.is_space\n",
    "\n",
    "def lemmatize(doc):\n",
    "    \"\"\"\n",
    "    function that tokenize the text, lemmatizes it and removes stop words.\n",
    "    \"\"\"\n",
    "    parsed_doc=nlp(doc)\n",
    "    lemm_doc = [token.lemma_ for token in parsed_doc\n",
    "                      if not punct_space(token) and (token.lemma_!= '-PRON-') and not(nlp.vocab[token.text].is_stop)]\n",
    "      \n",
    "    # write the transformed text\n",
    "    clean_text = u' '.join(lemm_doc)\n",
    "    return clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3bJs1sBXJPsA"
   },
   "outputs": [],
   "source": [
    "# we apply the lemmatization to all articles\n",
    "\n",
    "data['article_lemmatized']=data.article.map(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "asNQ9IoVJPsA",
    "outputId": "b672d948-f77e-4b2c-897f-6a9a667fc3be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: \n",
      "set(['politics', 'sport', 'tech', 'business', 'entertainment'])\n"
     ]
    }
   ],
   "source": [
    "# Types of categories\n",
    "print \"categories: \\n\",set(data.category)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjctVZa0JPsA",
    "outputId": "f84b6c25-a301-45a5-ca29-5ee31b7ac6c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>article_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>business</td>\n",
       "      <td>ad sale boost time warner profit quarterly pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>business</td>\n",
       "      <td>dollar gain greenspan speech dollar hit high l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>business</td>\n",
       "      <td>yukos unit buyer face loan claim owner embattl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>business</td>\n",
       "      <td>high fuel price hit ba 's profit british airwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>business</td>\n",
       "      <td>pernod takeover talk lift domecq share uk drin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>business</td>\n",
       "      <td>japan narrowly escape recession japan 's econo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>business</td>\n",
       "      <td>jobs growth slow create few job expect january...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>business</td>\n",
       "      <td>india call fair trade rule india attend g7 mee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>business</td>\n",
       "      <td>ethiopia 's crop production 24% ethiopia produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>business</td>\n",
       "      <td>court reject $ 280bn tobacco case government c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                 article_lemmatized\n",
       "0  business  ad sale boost time warner profit quarterly pro...\n",
       "1  business  dollar gain greenspan speech dollar hit high l...\n",
       "2  business  yukos unit buyer face loan claim owner embattl...\n",
       "3  business  high fuel price hit ba 's profit british airwa...\n",
       "4  business  pernod takeover talk lift domecq share uk drin...\n",
       "5  business  japan narrowly escape recession japan 's econo...\n",
       "6  business  jobs growth slow create few job expect january...\n",
       "7  business  india call fair trade rule india attend g7 mee...\n",
       "8  business  ethiopia 's crop production 24% ethiopia produ...\n",
       "9  business  court reject $ 280bn tobacco case government c..."
      ]
     },
     "execution_count": 278,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['category','article_lemmatized']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZhoQuK32JPsB"
   },
   "source": [
    "Split the data into train and test sets for the machine learning algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2VqnwTH7JPsB"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MDcZ2x4-lwnV",
    "outputId": "432867fb-3a05-4e62-de4e-63c65f06737f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2225,)"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['article_lemmatized'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I0xmVHfVJPsB",
    "outputId": "9b817fc7-30b5-452d-d0b9-1db11aef997a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of training 1335\n",
      "size of test 890\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['article_lemmatized'], data['category'], test_size=0.4, random_state=42)\n",
    "print \"size of training\",len(X_train)\n",
    "print \"size of test\",len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQ3pPuDfJPsB"
   },
   "source": [
    "We need to convert the text into a format that can be ingested by the algorithm. We use CountVectorizer to convert the collection of articles to a matrix of token counts. It will produce a matrix in compressed sparse row format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TKqKLPVIJPsC"
   },
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words='english', min_df=3)\n",
    "\n",
    "# we create a matrix for the training set\n",
    "cvec.fit(X_train)\n",
    "cvec_counts_train = cvec.transform(X_train)\n",
    "# we create a matrix for the test set\n",
    "cvec_counts_test=cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k7L4VPsDJPsC"
   },
   "source": [
    "Some info about the matrix of training set in compressed sparse row format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zJ6VlYB8JPsC",
    "outputId": "56e293c1-0563-4667-bdc5-ecf86f240ad6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (1335, 7702)\n",
      "nonzero count: 163747\n",
      "sparsity: 1.59%\n"
     ]
    }
   ],
   "source": [
    "print 'sparse matrix shape:', cvec_counts_train.shape\n",
    "print 'nonzero count:', cvec_counts_train.nnz\n",
    "print 'sparsity: %.2f%%' % (100.0 * cvec_counts_train.nnz / (cvec_counts_train.shape[0] * cvec_counts_train.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ad7IbzukJPsD"
   },
   "source": [
    "Instead of using word frequency alone we use tf/idf metric, which represents how important a word is to a document in a collection of corpus. It penalises words that tend to appear in all documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQcXp0mLJPsD"
   },
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(cvec_counts_train)\n",
    "X_test_tfidf = tfidf_transformer.fit_transform(cvec_counts_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lyZJfWp5JPsD"
   },
   "source": [
    "Now the data is ready to be ingested by a ML alforithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sFur9_sJPsE"
   },
   "source": [
    "# 2. Machine learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t_hmy-8OJPsE"
   },
   "source": [
    "The problem we are facing is a multi-class classification problem. We are going to try 2 ml algorithms: random forest and multinomial naive bayes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hP_nhSTxJPsE"
   },
   "source": [
    "# 2.1 Random forest:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-rzZGdLJPsF"
   },
   "source": [
    "Random forest classifier is an ensemble classification method that consists of training several decission trees\n",
    "on different subsamples of the data taking different subsets of features. The output class is selected by majority vote of the classes provided by all the trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65eWktkdJPsF"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn import metrics\n",
    "\n",
    "# training\n",
    "clf = RandomForestClassifier().fit(X_train_tfidf, y_train)\n",
    "\n",
    "# testing\n",
    "predicted=clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hCNBsbUBJPsG"
   },
   "source": [
    "How accurate is the model? We can calculate the global accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPqQ-YHRJPsG",
    "outputId": "db8d08ba-d21b-42ce-ecd2-f9928602a508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9168539325842696"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9YY5d5NUJPsG"
   },
   "source": [
    "We compute also other metrics for each class to evaluate the model like precision, recall or f1-score. We see that the precision is high: 0.91 in average and we can observe in the table bellow which is the precission, recall and f1-score for each class to evaluate how the model performs in classifying samples from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "46DpzqxfJPsG",
    "outputId": "ee6a1f86-abc3-4f75-b968-ecac481903b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.82      0.96      0.88       203\n",
      "entertainment       0.96      0.85      0.90       157\n",
      "     politics       0.94      0.90      0.92       167\n",
      "        sport       0.94      0.97      0.96       210\n",
      "         tech       0.99      0.87      0.92       153\n",
      "\n",
      "    micro avg       0.92      0.92      0.92       890\n",
      "    macro avg       0.93      0.91      0.92       890\n",
      " weighted avg       0.92      0.92      0.92       890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIX845iFJPsH"
   },
   "source": [
    "But this evaluation has been performed over one training and test data set chosen randomly. In order to be able to evaluate the performance of the model in a general basis we need to perform k-fold cross validation, which consists of partitioning the dataset in k subsets and using k-1 subsets for training and the one remaining for test and repeat this process until all the subsets has been used for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFOfCj2IJPsH"
   },
   "source": [
    "In order to make the count_vectorizer, tfidf-transformer, classifier easier to work with, \n",
    "scikit-learn provides a Pipeline class that helps run all the process together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "1AmqDZIEJPsH"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "text_clf = Pipeline([('vect', CountVectorizer(stop_words='english', min_df=3)),\\\n",
    "                     ('tfidf', TfidfTransformer()),\\\n",
    "                     ('clf', RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5yiBuq0qJPsH",
    "outputId": "3b71790a-8d9b-448a-eb52-cf18c49482d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('vect',\n",
       "  CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "          dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "          lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "          ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "          strip_accents=None, token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "          tokenizer=None, vocabulary=None)),\n",
       " ('tfidf', TfidfTransformer(norm=u'l2', smooth_idf=True, sublinear_tf=False,\n",
       "           use_idf=True)),\n",
       " ('clf',\n",
       "  RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "              max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_samples_split=2,\n",
       "              min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "              oob_score=False, random_state=None, verbose=0,\n",
       "              warm_start=False))]"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Description of steps of pipeline\n",
    "text_clf.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v5mNP_KbJPsI",
    "outputId": "0ad176fe-7892-4c25-9dd6-23d62606ddc5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words='english',\n",
       "     ...obs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))])"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf.fit(X_train, y_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eGa3o8QRJPsI",
    "outputId": "73291064-1f74-4789-cd00-dd41b2f77539"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy with 10-fold cross validation: 0.9231508117089758\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#cross_val_score evaluates a score by cross-validation. k-folds= parameter cv\n",
    "kfold_acc = cross_val_score(text_clf,data['article_lemmatized'], data['category'],cv=10,\n",
    "    scoring='accuracy')\n",
    "\n",
    "print \"mean accuracy with 10-fold cross validation:\", kfold_acc.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3p6c00wKJPsI"
   },
   "source": [
    "We can also extract what are the words that are more critical in differentiating the classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 331
    },
    "id": "uvNNAhvfJPsI",
    "outputId": "e3df247b-423f-4b1f-dcc2-757bebd98b36"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcf6a11cc10>"
      ]
     },
     "execution_count": 49,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feat_imp=list(text_clf.steps[2][1].feature_importances_)\n",
    "features=text_clf.steps[0][1].get_feature_names()\n",
    "result=pd.DataFrame(feat_imp,features)\n",
    "result.columns=(['feature importance'])\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "result.sort_values(['feature importance'],ascending=False).head(30).plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oGs6MkGFJPsJ"
   },
   "source": [
    "There are some parameters that affect the performance of random forest like the number of trees used, the number of predictors/features that random forest is allowed to try in each split (max_features), also the min_sample_leaf is the minimum number of samples required in one leaf. Leaf is the end node of a decision tree, a smaller leaf can make the model capture noise in train data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-7dijl8JPsJ"
   },
   "source": [
    "Let's change the number of trees (n_estimators parameter) and see if the results improve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TeTu8dnCJPsJ",
    "outputId": "8d29c151-9c99-4349-938b-68b2ca59cdd2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy with 10-fold cross validation: 0.96220978684181\n"
     ]
    }
   ],
   "source": [
    "text_clf2 = Pipeline([('vect', CountVectorizer(stop_words='english', min_df=3)),\\\n",
    "                     ('tfidf', TfidfTransformer()),\\\n",
    "                     ('clf', RandomForestClassifier(n_estimators=100))])\n",
    "\n",
    "text_clf2.fit(X_train, y_train)\n",
    "\n",
    "#cross_val_score evaluates a score by cross-validation. k-folds= parameter cv\n",
    "kfold_acc2 = cross_val_score(text_clf2,data['article_lemmatized'], data['category'],cv=10,\n",
    "    scoring='accuracy')\n",
    "\n",
    "print \"mean accuracy with 10-fold cross validation:\", kfold_acc2.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zR8LEFvxJPsK"
   },
   "source": [
    "We observe that the performance has improved after changing the number of trees.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Rugrmm5JPsK"
   },
   "source": [
    "We can also optimize the performance of the model by using grid search. With grid search we can select different values for the parameters and the function will return the set of parameters that make the model perform better in the metric chosen. In the example above we choose accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWywkLj1JPsK",
    "outputId": "b68550de-619c-4fd5-ef92-a9ca983cad34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 150, 'clf__min_samples_leaf': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"clf__n_estimators\": [100,150],\n",
    "              \"clf__max_features\": ['auto','sqrt',0.2],\n",
    "              \"clf__min_samples_leaf\": [2, 3, 50],\n",
    "              \"clf__criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(text_clf2, param_grid=param_grid, scoring='accuracy')\n",
    "start = time()\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WKhaXB5bJPsK",
    "outputId": "692c4fac-47c1-4b6d-e75b-c6b6544b8371"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best parameters values:\n",
      "{'clf__criterion': 'gini', 'clf__max_features': 'sqrt', 'clf__n_estimators': 150, 'clf__min_samples_leaf': 2}\n",
      "\n",
      "best score:\n",
      "0.960299625468\n"
     ]
    }
   ],
   "source": [
    "print 'best parameters values:\\n',grid_search.best_params_\n",
    "print\n",
    "#Mean cross-validated score of the best_estimator\n",
    "print 'best score:\\n',grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mrwaH10uJPsL"
   },
   "source": [
    "\n",
    "What we can infere from the results obtained using random forest is that the features selected for the classification, in this case the word counts or their equivalent tf/idf values are clearly discriminant between the 5 classes.\n",
    "\n",
    "\n",
    "Although Random Forest is performing very well in this case, usually Random Forest does not necessarily work well with sparse matrix such as the ones used in text classification. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "498jKFgoJPsL"
   },
   "source": [
    "Another model that is frequently used in text classification is multinomial naive bayes. We will try it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AqVuNwSEJPsM"
   },
   "source": [
    "# 2.2 Multinomial naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fskqvEQiJPsM"
   },
   "source": [
    "Naive Bayes is a probabilistic method that assumes independence between the features in our case the words in the vocabulary of the corpus of articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "Xyvqg7NxJPsM"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#In order to make the vectorizer => transformer => classifier easier to work with, \n",
    "#scikit-learn provides a Pipeline class that behaves like a compound classifier:\n",
    "\n",
    "text_clf_nb = Pipeline([('vect', CountVectorizer(stop_words='english', min_df=3)),\\\n",
    "                     ('tfidf', TfidfTransformer()),\\\n",
    "                     ('clf', MultinomialNB())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PDgtP74JPsN"
   },
   "outputs": [],
   "source": [
    "text_clf_nb.fit(X_train, y_train)  \n",
    "predicted = text_clf_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rfqUorDgJPsN",
    "outputId": "535862f4-76bc-43f2-da1d-564910dc9c20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "     business       0.94      1.00      0.97       203\n",
      "entertainment       0.99      0.92      0.95       157\n",
      "     politics       0.94      0.95      0.94       167\n",
      "        sport       1.00      1.00      1.00       210\n",
      "         tech       0.97      0.96      0.97       153\n",
      "\n",
      "    micro avg       0.97      0.97      0.97       890\n",
      "    macro avg       0.97      0.96      0.97       890\n",
      " weighted avg       0.97      0.97      0.97       890\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ntyv1CivJPsN"
   },
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(text_clf_nb, 'text_clf_nb.pkl') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d20ZtwXUJPsO"
   },
   "source": [
    "k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjkq3Ps0JPsO",
    "outputId": "3748d20e-3f1b-4945-f575-16f410dd8c7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean accuracy with 10-fold cross validation: 0.968534738733\n"
     ]
    }
   ],
   "source": [
    "#cross_val_score evaluates a score by cross-validation. k-folds= parameter cv\n",
    "\n",
    "kfold_acc_nb = cross_val_score(text_clf_nb,X_train,y_train,cv=10,\n",
    "    scoring='accuracy')\n",
    "\n",
    "print \"mean accuracy with 10-fold cross validation:\", kfold_acc_nb.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7WQ4Y-GJPsO"
   },
   "source": [
    "We observe that the accuracy is similar to random forest, slightly higher with the multinomial naive bayes classifier (NBC). We can then assert that for this particular problem both methods perform really well. \n",
    "\n",
    "Something worth mentioning is that the speed of NBC is greater than RF, which can be of importance in case there is a need of escalating the problem to a larger number of articles.\n",
    "\n",
    "One of the things that we could have used is ngrams of 2 or 3 words as features for the model. To test this, tests have been performed adding the parameter: ngram_range=(1,3) and ngram_range=(1,2) to the CountVectorizer function but the peformance did not improve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YZGZNCaYJPsO"
   },
   "source": [
    "# One step more of validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ghuJgohJJPsP"
   },
   "source": [
    "It is always good to validate the performance of a model with a validation dataset. We can obtain a validation dataset using the second dataset in http://mlg.ucd.ie/datasets/bbc.html that contains articles from BBC Sports labeled with sport categories.\n",
    "\n",
    "We can use this dataset to validate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "XfBQFqPbJPsP"
   },
   "outputs": [],
   "source": [
    "sports=extract_articles('/content/drive/MyDrive/BBC_articles/bbcsport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oB8-EB-IJPsP",
    "outputId": "6378ce12-57b0-4281-ad00-9d226496a084"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>article</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>athletics</td>\n",
       "      <td>Claxton hunting first major medal  British hur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>athletics</td>\n",
       "      <td>O'Sullivan could run in Worlds  Sonia O'Sulliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>athletics</td>\n",
       "      <td>Greene sets sights on world title  Maurice Gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>athletics</td>\n",
       "      <td>IAAF launches fight against drugs  The IAAF - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>athletics</td>\n",
       "      <td>Dibaba breaks 5,000m world record  Ethiopia's ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    category                                            article\n",
       "0  athletics  Claxton hunting first major medal  British hur...\n",
       "1  athletics  O'Sullivan could run in Worlds  Sonia O'Sulliv...\n",
       "2  athletics  Greene sets sights on world title  Maurice Gre...\n",
       "3  athletics  IAAF launches fight against drugs  The IAAF - ...\n",
       "4  athletics  Dibaba breaks 5,000m world record  Ethiopia's ..."
      ]
     },
     "execution_count": 239,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sports.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhqV3PRDJPsP",
    "outputId": "510f74ef-68eb-4627-91e9-0ba13fb9d9ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sports categories: set(['tennis', 'athletics', 'football', 'rugby', 'cricket'])\n"
     ]
    }
   ],
   "source": [
    "print 'sports categories:',set(sports.category)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVS8AUc4JPsP"
   },
   "source": [
    "Text cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jtOoHxZfJPsQ"
   },
   "outputs": [],
   "source": [
    "# converting to unicode\n",
    "sports['article'] = sports['article'].apply(lambda x: x.decode('utf-8','ignore'))\n",
    "\n",
    "# lemmatization\n",
    "sports['article_lemmatized']=sports.article.map(lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftASabnEJPsQ"
   },
   "source": [
    "It could be that some sport articles in the training dataset are contained in the sports dataset. In order to avoid having articles in the validation dataset that have been used for training in the previous steps we exclude those articles that appear in both. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r6BpZe26JPsQ",
    "outputId": "84e25ceb-52b9-4516-b56d-a4d788b55f59"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of sports articles in the whole dataset: 511\n",
      "number of articles in the sports dataset 737\n"
     ]
    }
   ],
   "source": [
    "print 'number of sports articles in the whole dataset:',data[data['category']=='sport'].shape[0]\n",
    "print 'number of articles in the sports dataset',sports.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAAqT688JPsQ",
    "outputId": "ab6eff35-1deb-452e-a695-d07715ea18a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of articles not used in the training: 222\n"
     ]
    }
   ],
   "source": [
    "#concatenate the two dataframes and remove the duplicates\n",
    "concat=pd.concat([data[data.category=='sport'][['category','article','article_lemmatized']],sports[['category','article','article_lemmatized']]])\n",
    "\n",
    "unique_sport=concat[(concat.duplicated(subset=['article'])==False)&(concat.category!='sport')]\n",
    "print 'number of articles not used in the training:',unique_sport.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rEsqqCafJPsR",
    "outputId": "68511a53-180d-4d63-e1d2-175e8d2b6733"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the model: 0.945945945946\n"
     ]
    }
   ],
   "source": [
    "#predict the class with the multinomial naive Bayes trained classifier\n",
    "\n",
    "predicted=text_clf_nb.predict(unique_sport['article_lemmatized'])\n",
    "\n",
    "#accuracy: number of articles labeled with sport\n",
    "print 'accuracy of the model:',list(predicted).count('sport')/len(predicted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ulRCBnisJPsR"
   },
   "source": [
    "We can confirm that the model works well also for this validation dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b7RP8m1eJPsR"
   },
   "source": [
    "# Example of prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0vd_eA0yJPsR",
    "outputId": "ecce18d9-23c5-4aab-f096-af87f55e313a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'Beckham virus spotted on the net  Virus writers are trading on interest in David Beckham to distribute their malicious wares.  Messages are circulating widely that purport to have evidence of the England captain in a compromising position. But anyone visiting the website mentioned in the message will not see pictures of Mr Beckham but will have their computer infected by a virus. The pernicious program opens a backdoor on a computer so it can be controlled remotely by malicious hackers.  The appearance of the Beckham Windows trojan is just another example in a long line of viruses that trade on interest in celebrities in an attempt to fuel their spread. Tennis player Anna Kournikova, popstars Britney Spears and Avril Lavigne as well as Arnold Schwarzenegger have all been used in the past to try to con people into opening infected files. The huge amount of interest in Mr Beckham and his private life and the large number of messages posted to discussion groups on the net might mean that the malicious program catches a lot of people out. \"The public\\'s appetite for salacious gossip about the private life of the Beckhams might lead some into an unpleasant computer infection,\" said Graham Cluley from anti-virus firm Sophos. Simply opening the message will not infect a user\\'s PC. But anyone visiting the website it mentions who then downloads and opens the fake image file stored on that site will be infected. The program that installs itself is called the Hackarmy trojan and it tries to recruit PCs into so-called \\'bot networks that are often used to distribute spam mail messages or to launch attacks across the web. Computers running Microsoft Windows 95, 98, 2000, NT and XP are vulnerable to this trojan. Many anti-virus programs have been able to detect this trojan since it first appeared early this year and have regularly been updated to catch new variants.'"
      ]
     },
     "execution_count": 245,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we select one article of the test set\n",
    "ind1=X_test.index[400]\n",
    "data.article[ind1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zm9fHiY5JPsR",
    "outputId": "f0f46f54-e21e-466f-d540-5beb7cf6f152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted class is: tech \n",
      "and the true one was: tech\n"
     ]
    }
   ],
   "source": [
    "class_=text_clf_nb.predict([data.article[ind1]])[0]\n",
    "print \"the predicted class is:\",class_ , \"\\nand the true one was:\",data['category'][ind1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6BG5N-dJPsS"
   },
   "source": [
    "Another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qmas0pZ7JPsS",
    "outputId": "fec3e437-d821-4186-f386-8ad1fa9aa78b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u\"Millions go missing at China bank  Two senior officials at one of China's top commercial banks have reportedly disappeared after funds worth up to $120m (\\xa364m) went missing.  The pair both worked at Bank of China in the northern city of Harbin, the South China Morning Post reported. The latest scandal at Bank of China will do nothing to reassure foreign investors that China's big four banks are ready for international listings. Government policy sees the bank listings as vital economic reforms. Bank of China is one of two frontrunners in the race to list overseas. The other is China Construction Bank. Both are expected to list abroad during 2005.  They shared a $45bn state bailout in 2003, to help clean up their balance sheets in preparation for a foreign stock market debut.  However, a report in the China-published Economic Observer said on Monday that the two banks may have scrapped plans to list in New York because of the cost of meeting regulatory requirements imposed since the Enron scandal. Bank of China is the country's biggest foreign exchange dealer, while China Construction Bank is the largest deposit holder. China's banking sector is burdened with at least $190bn of bad debt according to official data, though most observers believe the true figure is far higher. Officially, one in five loans is not being repaid. Attempts to strengthen internal controls and tighten lending policies have uncovered a succession of scandals involving embezzlement by bank officials and loans-for-favours. The most high-profile case involved the ex-president of Bank of China, Wang Xuebing, jailed for 12 years in 2003. Although, he committed the offences whilst running Bank of China in New York, Mr Wang was head of China Construction Bank when the scandal broke. Earlier this month, a China Construction Bank branch manager was jailed for life in a separate case.  China's banks used to act as cash offices for state enterprises and did not require checks on credit worthiness. The introduction of market reforms has been accompanied by attempts to modernise the banking sector, but links between banks and local government remain strong. Last year, China's premier, Wen Jiabao, targeted bank lending practices in a series of speeches, and regulators ordered all big loans to be scrutinised, in an attempt to cool down irresponsible lending. China's leaders see reforming the top four banks as vital to distribute capital to profitable companies and protect the health of China's economic boom. But two problems persist. First, inefficient state enterprises continue to receive protection from bankruptcy because they employ large numbers of people. Second, many questionable loans come not from the big four, but from smaller banks. Another high profile financial firm, China Life, is facing shareholder lawsuits and a probe by the US Securities and Exchange Commission following its 2004 New York listing over its failure to disclose accounting irregularities at its parent company.\""
      ]
     },
     "execution_count": 247,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we select one article of the test set\n",
    "ind1=X_test.index[800]\n",
    "data.article[ind1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BygyHu7JPsS",
    "outputId": "da1079ef-829a-4333-d31b-f8892bc8de82"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the predicted class is: business \n",
      "and the true one was: business\n"
     ]
    }
   ],
   "source": [
    "class_=text_clf_nb.predict([data.article[ind1]])[0]\n",
    "print \"the predicted class is:\",class_ , \"\\nand the true one was:\",data['category'][ind1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMiDUocBJPsS"
   },
   "source": [
    "# What else can we extract from this dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEKdgU1PJPsT"
   },
   "source": [
    "We have built supervised learning models that learn to classify articles into predefined categories. Now we can try to extract natural topics within the articles. We explore now how the unsupervised learning algorithm LDA can help us. LDA is a generative probabilistic model that needs to know the number of topics a priori. It assigns a probability to each word in the corpus of documents to belong to a topic. This way we can find groups of words that tend to appear in certain groups of articles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "PpB3qBX3JPsT"
   },
   "source": [
    "# LDA - topic modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ptF4Tni_JPsT"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.corpora import Dictionary, MmCorpus\n",
    "#from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.models import Phrases, LdaModel\n",
    "#from gensim.models.word2vec import LineSentence\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "import cPickle as pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D3PpunyDJPsT"
   },
   "outputs": [],
   "source": [
    "#The function Dictionary creates a dictionary of terms from the docs. It needs as input a list of list of tokens.\n",
    "#We need to split the documents into lists of words\n",
    "\n",
    "splitter = lambda x: x.split()\n",
    "doc_list=data.article_lemmatized.apply(splitter)\n",
    "# Phrases identifies multi word expressions co-ocurring in multiple docs (n-grams)\n",
    "phrases = Phrases(doc_list)\n",
    "# Phraser replace the n-grams found in the documents\n",
    "bigrams = Phraser(phrases)\n",
    "# creation of the dictionary for LDA input\n",
    "dic= Dictionary(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "dCGYABXLJPsT"
   },
   "outputs": [],
   "source": [
    "dic.filter_extremes(no_below=1)#, no_above=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PnZIL62uJPsT"
   },
   "source": [
    "This is an exploratory phase so we select 20 topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "ZwBdV_yGJPsU"
   },
   "outputs": [],
   "source": [
    "#use the dictionary to create a document-term matrix\n",
    "corpus = [dic.doc2bow(doc) for doc in doc_list]\n",
    "\n",
    "lda_model = LdaModel(corpus, num_topics=20, id2word=dic, update_every=1, chunksize=1000, passes=50)\n",
    "lda_model.save('lda_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThH2Xwp5JPsU"
   },
   "outputs": [],
   "source": [
    "# load model in order not to retrain\n",
    "lda_model = gensim.models.ldamodel.LdaModel.load('lda_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "kTzkc7-oJPsU"
   },
   "outputs": [],
   "source": [
    "lda_model.show_topic(topicid=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iDS2z98hJPsU",
    "outputId": "cf1db271-2fa2-457a-9daf-4d76481c5251"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012*\"india\"</td>\n",
       "      <td>0.013*\"dollar\"</td>\n",
       "      <td>0.014*\"be\"</td>\n",
       "      <td>0.038*\"mobile\"</td>\n",
       "      <td>0.071*\"game\"</td>\n",
       "      <td>0.027*\"mr\"</td>\n",
       "      <td>0.017*\"tv\"</td>\n",
       "      <td>0.037*\"mac\"</td>\n",
       "      <td>0.027*\"film\"</td>\n",
       "      <td>0.012*\"$\"</td>\n",
       "      <td>0.018*\"win\"</td>\n",
       "      <td>0.060*\"g\"</td>\n",
       "      <td>0.016*\"file\"</td>\n",
       "      <td>0.017*\"be\"</td>\n",
       "      <td>0.017*\"digital\"</td>\n",
       "      <td>0.034*\"good\"</td>\n",
       "      <td>0.015*\"wales\"</td>\n",
       "      <td>0.013*\"fraud\"</td>\n",
       "      <td>0.014*\"net\"</td>\n",
       "      <td>0.015*\"m\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.012*\"protocol\"</td>\n",
       "      <td>0.012*\"bush\"</td>\n",
       "      <td>0.011*\"play\"</td>\n",
       "      <td>0.035*\"phone\"</td>\n",
       "      <td>0.020*\"gaming\"</td>\n",
       "      <td>0.012*\"government\"</td>\n",
       "      <td>0.014*\"game\"</td>\n",
       "      <td>0.013*\"hunt\"</td>\n",
       "      <td>0.014*\"music\"</td>\n",
       "      <td>0.010*\"£\"</td>\n",
       "      <td>0.016*\"6\"</td>\n",
       "      <td>0.055*\"3\"</td>\n",
       "      <td>0.013*\"system\"</td>\n",
       "      <td>0.013*\"people\"</td>\n",
       "      <td>0.016*\"music\"</td>\n",
       "      <td>0.021*\"win\"</td>\n",
       "      <td>0.014*\"england\"</td>\n",
       "      <td>0.012*\"guilty\"</td>\n",
       "      <td>0.014*\"user\"</td>\n",
       "      <td>0.015*\"£\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011*\"indian\"</td>\n",
       "      <td>0.011*\"deficit\"</td>\n",
       "      <td>0.009*\"player\"</td>\n",
       "      <td>0.014*\"people\"</td>\n",
       "      <td>0.016*\"dvd\"</td>\n",
       "      <td>0.010*\"party\"</td>\n",
       "      <td>0.012*\"high\"</td>\n",
       "      <td>0.011*\"light\"</td>\n",
       "      <td>0.013*\"star\"</td>\n",
       "      <td>0.009*\"market\"</td>\n",
       "      <td>0.015*\"m\"</td>\n",
       "      <td>0.020*\"seed\"</td>\n",
       "      <td>0.010*\"apple\"</td>\n",
       "      <td>0.010*\"not\"</td>\n",
       "      <td>0.014*\"service\"</td>\n",
       "      <td>0.017*\"award\"</td>\n",
       "      <td>0.013*\"ireland\"</td>\n",
       "      <td>0.010*\"deutsche\"</td>\n",
       "      <td>0.012*\"mail\"</td>\n",
       "      <td>0.010*\"coach\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010*\"systems\"</td>\n",
       "      <td>0.009*\"growth\"</td>\n",
       "      <td>0.009*\"game\"</td>\n",
       "      <td>0.011*\"technology\"</td>\n",
       "      <td>0.015*\"play\"</td>\n",
       "      <td>0.010*\"labour\"</td>\n",
       "      <td>0.012*\"device\"</td>\n",
       "      <td>0.009*\"mr\"</td>\n",
       "      <td>0.010*\"include\"</td>\n",
       "      <td>0.009*\"m\"</td>\n",
       "      <td>0.011*\"world\"</td>\n",
       "      <td>0.020*\"7\"</td>\n",
       "      <td>0.010*\"legal\"</td>\n",
       "      <td>0.010*\"work\"</td>\n",
       "      <td>0.014*\"technology\"</td>\n",
       "      <td>0.013*\"film\"</td>\n",
       "      <td>0.011*\"half\"</td>\n",
       "      <td>0.010*\"lse\"</td>\n",
       "      <td>0.012*\"virus\"</td>\n",
       "      <td>0.008*\"mr\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.009*\"telekom\"</td>\n",
       "      <td>0.009*\"figure\"</td>\n",
       "      <td>0.008*\"not\"</td>\n",
       "      <td>0.011*\"use\"</td>\n",
       "      <td>0.011*\"title\"</td>\n",
       "      <td>0.010*\"election\"</td>\n",
       "      <td>0.011*\"sony\"</td>\n",
       "      <td>0.008*\"keyboard\"</td>\n",
       "      <td>0.010*\"band\"</td>\n",
       "      <td>0.008*\"company\"</td>\n",
       "      <td>0.011*\"final\"</td>\n",
       "      <td>0.010*\"hsdpa\"</td>\n",
       "      <td>0.009*\"company\"</td>\n",
       "      <td>0.009*\"time\"</td>\n",
       "      <td>0.014*\"people\"</td>\n",
       "      <td>0.008*\"v\"</td>\n",
       "      <td>0.011*\"rugby\"</td>\n",
       "      <td>0.009*\"exchange\"</td>\n",
       "      <td>0.011*\"e\"</td>\n",
       "      <td>0.006*\"$\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.009*\"boeing\"</td>\n",
       "      <td>0.009*\"sale\"</td>\n",
       "      <td>0.008*\"club\"</td>\n",
       "      <td>0.009*\"service\"</td>\n",
       "      <td>0.011*\"player\"</td>\n",
       "      <td>0.008*\"minister\"</td>\n",
       "      <td>0.010*\"console\"</td>\n",
       "      <td>0.008*\"hunting\"</td>\n",
       "      <td>0.009*\"uk\"</td>\n",
       "      <td>0.007*\"rise\"</td>\n",
       "      <td>0.011*\"set\"</td>\n",
       "      <td>0.010*\"speed\"</td>\n",
       "      <td>0.009*\"software\"</td>\n",
       "      <td>0.009*\"like\"</td>\n",
       "      <td>0.012*\"broadband\"</td>\n",
       "      <td>0.007*\"actor\"</td>\n",
       "      <td>0.009*\"france\"</td>\n",
       "      <td>0.009*\"london\"</td>\n",
       "      <td>0.011*\"site\"</td>\n",
       "      <td>0.006*\"work\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.008*\"austria\"</td>\n",
       "      <td>0.007*\"economy\"</td>\n",
       "      <td>0.007*\"time\"</td>\n",
       "      <td>0.008*\"camera\"</td>\n",
       "      <td>0.011*\"world\"</td>\n",
       "      <td>0.008*\"blair\"</td>\n",
       "      <td>0.009*\"new\"</td>\n",
       "      <td>0.008*\"laser\"</td>\n",
       "      <td>0.009*\"number\"</td>\n",
       "      <td>0.007*\"bank\"</td>\n",
       "      <td>0.010*\"title\"</td>\n",
       "      <td>0.009*\"player\"</td>\n",
       "      <td>0.009*\"firm\"</td>\n",
       "      <td>0.008*\"think\"</td>\n",
       "      <td>0.010*\"player\"</td>\n",
       "      <td>0.007*\"director\"</td>\n",
       "      <td>0.009*\"minute\"</td>\n",
       "      <td>0.009*\"charge\"</td>\n",
       "      <td>0.011*\"search\"</td>\n",
       "      <td>0.006*\"week\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.007*\"plane\"</td>\n",
       "      <td>0.007*\"rise\"</td>\n",
       "      <td>0.007*\"team\"</td>\n",
       "      <td>0.007*\"handset\"</td>\n",
       "      <td>0.010*\"2\"</td>\n",
       "      <td>0.007*\"people\"</td>\n",
       "      <td>0.009*\"definition\"</td>\n",
       "      <td>0.007*\"silicon\"</td>\n",
       "      <td>0.009*\"award\"</td>\n",
       "      <td>0.007*\"share\"</td>\n",
       "      <td>0.008*\"open\"</td>\n",
       "      <td>0.008*\"second\"</td>\n",
       "      <td>0.008*\"law\"</td>\n",
       "      <td>0.006*\"world\"</td>\n",
       "      <td>0.009*\"gadget\"</td>\n",
       "      <td>0.007*\"british\"</td>\n",
       "      <td>0.008*\"try\"</td>\n",
       "      <td>0.008*\"executive\"</td>\n",
       "      <td>0.010*\"software\"</td>\n",
       "      <td>0.005*\"aid\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.007*\"tobacco\"</td>\n",
       "      <td>0.006*\"2004\"</td>\n",
       "      <td>0.006*\"come\"</td>\n",
       "      <td>0.007*\"company\"</td>\n",
       "      <td>0.009*\"online\"</td>\n",
       "      <td>0.006*\"plan\"</td>\n",
       "      <td>0.009*\"gamer\"</td>\n",
       "      <td>0.007*\"animal\"</td>\n",
       "      <td>0.008*\"m\"</td>\n",
       "      <td>0.007*\"firm\"</td>\n",
       "      <td>0.008*\"second\"</td>\n",
       "      <td>0.008*\"network\"</td>\n",
       "      <td>0.008*\"court\"</td>\n",
       "      <td>0.006*\"life\"</td>\n",
       "      <td>0.009*\"pc\"</td>\n",
       "      <td>0.006*\"prize\"</td>\n",
       "      <td>0.008*\"game\"</td>\n",
       "      <td>0.008*\"boerse\"</td>\n",
       "      <td>0.010*\"security\"</td>\n",
       "      <td>0.005*\"pension\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.007*\"flight\"</td>\n",
       "      <td>0.006*\"steam\"</td>\n",
       "      <td>0.006*\"go\"</td>\n",
       "      <td>0.007*\"device\"</td>\n",
       "      <td>0.008*\"release\"</td>\n",
       "      <td>0.006*\"tell\"</td>\n",
       "      <td>0.008*\"mr\"</td>\n",
       "      <td>0.007*\"vodafone\"</td>\n",
       "      <td>0.008*\"album\"</td>\n",
       "      <td>0.007*\"price\"</td>\n",
       "      <td>0.008*\"champion\"</td>\n",
       "      <td>0.008*\"mp3\"</td>\n",
       "      <td>0.007*\"network\"</td>\n",
       "      <td>0.005*\"go\"</td>\n",
       "      <td>0.008*\"consumer\"</td>\n",
       "      <td>0.006*\"star\"</td>\n",
       "      <td>0.007*\"squad\"</td>\n",
       "      <td>0.007*\"york\"</td>\n",
       "      <td>0.009*\"people\"</td>\n",
       "      <td>0.005*\"take\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.006*\"factory\"</td>\n",
       "      <td>0.006*\"fall\"</td>\n",
       "      <td>0.006*\"good\"</td>\n",
       "      <td>0.007*\"network\"</td>\n",
       "      <td>0.007*\"hop\"</td>\n",
       "      <td>0.006*\"brown\"</td>\n",
       "      <td>0.008*\"video\"</td>\n",
       "      <td>0.007*\"shoot\"</td>\n",
       "      <td>0.008*\"song\"</td>\n",
       "      <td>0.006*\"china\"</td>\n",
       "      <td>0.007*\"time\"</td>\n",
       "      <td>0.007*\"conte\"</td>\n",
       "      <td>0.007*\"peer\"</td>\n",
       "      <td>0.005*\"way\"</td>\n",
       "      <td>0.007*\"uk\"</td>\n",
       "      <td>0.006*\"slam\"</td>\n",
       "      <td>0.007*\"domain\"</td>\n",
       "      <td>0.007*\"radcliffe\"</td>\n",
       "      <td>0.009*\"information\"</td>\n",
       "      <td>0.005*\"pay\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.006*\"air\"</td>\n",
       "      <td>0.005*\"economic\"</td>\n",
       "      <td>0.006*\"win\"</td>\n",
       "      <td>0.006*\"number\"</td>\n",
       "      <td>0.007*\"technology\"</td>\n",
       "      <td>0.005*\"issue\"</td>\n",
       "      <td>0.008*\"film\"</td>\n",
       "      <td>0.007*\"help\"</td>\n",
       "      <td>0.007*\"chart\"</td>\n",
       "      <td>0.006*\"sale\"</td>\n",
       "      <td>0.007*\"race\"</td>\n",
       "      <td>0.007*\"siemens\"</td>\n",
       "      <td>0.007*\"new\"</td>\n",
       "      <td>0.005*\"get\"</td>\n",
       "      <td>0.007*\"market\"</td>\n",
       "      <td>0.006*\"category\"</td>\n",
       "      <td>0.006*\"ukip\"</td>\n",
       "      <td>0.007*\"bid\"</td>\n",
       "      <td>0.008*\"computer\"</td>\n",
       "      <td>0.004*\"woman\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.006*\"aircraft\"</td>\n",
       "      <td>0.005*\"federal\"</td>\n",
       "      <td>0.006*\"want\"</td>\n",
       "      <td>0.006*\"send\"</td>\n",
       "      <td>0.006*\"ray\"</td>\n",
       "      <td>0.005*\"public\"</td>\n",
       "      <td>0.008*\"nintendo\"</td>\n",
       "      <td>0.006*\"learn\"</td>\n",
       "      <td>0.006*\"take\"</td>\n",
       "      <td>0.005*\"economy\"</td>\n",
       "      <td>0.006*\"match\"</td>\n",
       "      <td>0.007*\"american\"</td>\n",
       "      <td>0.006*\"people\"</td>\n",
       "      <td>0.005*\"old\"</td>\n",
       "      <td>0.007*\"offer\"</td>\n",
       "      <td>0.005*\"actress\"</td>\n",
       "      <td>0.006*\"kilroy\"</td>\n",
       "      <td>0.007*\"plead\"</td>\n",
       "      <td>0.008*\"attack\"</td>\n",
       "      <td>0.004*\"union\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.006*\"bypass\"</td>\n",
       "      <td>0.005*\"release\"</td>\n",
       "      <td>0.006*\"cup\"</td>\n",
       "      <td>0.005*\"patent\"</td>\n",
       "      <td>0.006*\"be\"</td>\n",
       "      <td>0.005*\"new\"</td>\n",
       "      <td>0.007*\"dvd\"</td>\n",
       "      <td>0.006*\"language\"</td>\n",
       "      <td>0.006*\"record\"</td>\n",
       "      <td>0.005*\"country\"</td>\n",
       "      <td>0.006*\"play\"</td>\n",
       "      <td>0.006*\"high\"</td>\n",
       "      <td>0.006*\"spyware\"</td>\n",
       "      <td>0.005*\"radio\"</td>\n",
       "      <td>0.006*\"tv\"</td>\n",
       "      <td>0.005*\"man\"</td>\n",
       "      <td>0.006*\"italy\"</td>\n",
       "      <td>0.006*\"investigation\"</td>\n",
       "      <td>0.008*\"microsoft\"</td>\n",
       "      <td>0.004*\"president\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.005*\"airbus\"</td>\n",
       "      <td>0.005*\"crude\"</td>\n",
       "      <td>0.005*\"think\"</td>\n",
       "      <td>0.005*\"customer\"</td>\n",
       "      <td>0.006*\"sound\"</td>\n",
       "      <td>0.005*\"uk\"</td>\n",
       "      <td>0.006*\"programme\"</td>\n",
       "      <td>0.005*\"barcelona\"</td>\n",
       "      <td>0.006*\"new\"</td>\n",
       "      <td>0.005*\"rate\"</td>\n",
       "      <td>0.006*\"good\"</td>\n",
       "      <td>0.006*\"30\"</td>\n",
       "      <td>0.006*\"case\"</td>\n",
       "      <td>0.005*\"good\"</td>\n",
       "      <td>0.006*\"new\"</td>\n",
       "      <td>0.005*\"favourite\"</td>\n",
       "      <td>0.006*\"ball\"</td>\n",
       "      <td>0.006*\"sec\"</td>\n",
       "      <td>0.008*\"program\"</td>\n",
       "      <td>0.004*\"age\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0                   1                 2   \\\n",
       "0       0.012*\"india\"      0.013*\"dollar\"        0.014*\"be\"    \n",
       "1    0.012*\"protocol\"        0.012*\"bush\"      0.011*\"play\"    \n",
       "2      0.011*\"indian\"     0.011*\"deficit\"    0.009*\"player\"    \n",
       "3     0.010*\"systems\"      0.009*\"growth\"      0.009*\"game\"    \n",
       "4     0.009*\"telekom\"      0.009*\"figure\"       0.008*\"not\"    \n",
       "5      0.009*\"boeing\"        0.009*\"sale\"      0.008*\"club\"    \n",
       "6     0.008*\"austria\"     0.007*\"economy\"      0.007*\"time\"    \n",
       "7       0.007*\"plane\"        0.007*\"rise\"      0.007*\"team\"    \n",
       "8     0.007*\"tobacco\"        0.006*\"2004\"      0.006*\"come\"    \n",
       "9      0.007*\"flight\"       0.006*\"steam\"        0.006*\"go\"    \n",
       "10    0.006*\"factory\"        0.006*\"fall\"      0.006*\"good\"    \n",
       "11        0.006*\"air\"    0.005*\"economic\"       0.006*\"win\"    \n",
       "12   0.006*\"aircraft\"     0.005*\"federal\"      0.006*\"want\"    \n",
       "13     0.006*\"bypass\"     0.005*\"release\"       0.006*\"cup\"    \n",
       "14      0.005*\"airbus\"       0.005*\"crude\"     0.005*\"think\"   \n",
       "\n",
       "                      3                     4                     5   \\\n",
       "0        0.038*\"mobile\"          0.071*\"game\"            0.027*\"mr\"    \n",
       "1         0.035*\"phone\"        0.020*\"gaming\"    0.012*\"government\"    \n",
       "2        0.014*\"people\"           0.016*\"dvd\"         0.010*\"party\"    \n",
       "3    0.011*\"technology\"          0.015*\"play\"        0.010*\"labour\"    \n",
       "4           0.011*\"use\"         0.011*\"title\"      0.010*\"election\"    \n",
       "5       0.009*\"service\"        0.011*\"player\"      0.008*\"minister\"    \n",
       "6        0.008*\"camera\"         0.011*\"world\"         0.008*\"blair\"    \n",
       "7       0.007*\"handset\"             0.010*\"2\"        0.007*\"people\"    \n",
       "8       0.007*\"company\"        0.009*\"online\"          0.006*\"plan\"    \n",
       "9        0.007*\"device\"       0.008*\"release\"          0.006*\"tell\"    \n",
       "10      0.007*\"network\"           0.007*\"hop\"         0.006*\"brown\"    \n",
       "11       0.006*\"number\"    0.007*\"technology\"         0.005*\"issue\"    \n",
       "12         0.006*\"send\"           0.006*\"ray\"        0.005*\"public\"    \n",
       "13       0.005*\"patent\"            0.006*\"be\"           0.005*\"new\"    \n",
       "14      0.005*\"customer\"         0.006*\"sound\"            0.005*\"uk\"   \n",
       "\n",
       "                      6                   7                  8   \\\n",
       "0            0.017*\"tv\"         0.037*\"mac\"       0.027*\"film\"    \n",
       "1          0.014*\"game\"        0.013*\"hunt\"      0.014*\"music\"    \n",
       "2          0.012*\"high\"       0.011*\"light\"       0.013*\"star\"    \n",
       "3        0.012*\"device\"          0.009*\"mr\"    0.010*\"include\"    \n",
       "4          0.011*\"sony\"    0.008*\"keyboard\"       0.010*\"band\"    \n",
       "5       0.010*\"console\"     0.008*\"hunting\"         0.009*\"uk\"    \n",
       "6           0.009*\"new\"       0.008*\"laser\"     0.009*\"number\"    \n",
       "7    0.009*\"definition\"     0.007*\"silicon\"      0.009*\"award\"    \n",
       "8         0.009*\"gamer\"      0.007*\"animal\"          0.008*\"m\"    \n",
       "9            0.008*\"mr\"    0.007*\"vodafone\"      0.008*\"album\"    \n",
       "10        0.008*\"video\"       0.007*\"shoot\"       0.008*\"song\"    \n",
       "11         0.008*\"film\"        0.007*\"help\"      0.007*\"chart\"    \n",
       "12     0.008*\"nintendo\"       0.006*\"learn\"       0.006*\"take\"    \n",
       "13          0.007*\"dvd\"    0.006*\"language\"     0.006*\"record\"    \n",
       "14     0.006*\"programme\"   0.005*\"barcelona\"        0.006*\"new\"   \n",
       "\n",
       "                   9                   10                  11  \\\n",
       "0          0.012*\"$\"         0.018*\"win\"           0.060*\"g\"    \n",
       "1          0.010*\"£\"           0.016*\"6\"           0.055*\"3\"    \n",
       "2     0.009*\"market\"           0.015*\"m\"        0.020*\"seed\"    \n",
       "3          0.009*\"m\"       0.011*\"world\"           0.020*\"7\"    \n",
       "4    0.008*\"company\"       0.011*\"final\"       0.010*\"hsdpa\"    \n",
       "5       0.007*\"rise\"         0.011*\"set\"       0.010*\"speed\"    \n",
       "6       0.007*\"bank\"       0.010*\"title\"      0.009*\"player\"    \n",
       "7      0.007*\"share\"        0.008*\"open\"      0.008*\"second\"    \n",
       "8       0.007*\"firm\"      0.008*\"second\"     0.008*\"network\"    \n",
       "9      0.007*\"price\"    0.008*\"champion\"         0.008*\"mp3\"    \n",
       "10     0.006*\"china\"        0.007*\"time\"       0.007*\"conte\"    \n",
       "11      0.006*\"sale\"        0.007*\"race\"     0.007*\"siemens\"    \n",
       "12   0.005*\"economy\"       0.006*\"match\"    0.007*\"american\"    \n",
       "13   0.005*\"country\"        0.006*\"play\"        0.006*\"high\"    \n",
       "14       0.005*\"rate\"        0.006*\"good\"          0.006*\"30\"   \n",
       "\n",
       "                    12                13                    14  \\\n",
       "0        0.016*\"file\"        0.017*\"be\"       0.017*\"digital\"    \n",
       "1      0.013*\"system\"    0.013*\"people\"         0.016*\"music\"    \n",
       "2       0.010*\"apple\"       0.010*\"not\"       0.014*\"service\"    \n",
       "3       0.010*\"legal\"      0.010*\"work\"    0.014*\"technology\"    \n",
       "4     0.009*\"company\"      0.009*\"time\"        0.014*\"people\"    \n",
       "5    0.009*\"software\"      0.009*\"like\"     0.012*\"broadband\"    \n",
       "6        0.009*\"firm\"     0.008*\"think\"        0.010*\"player\"    \n",
       "7         0.008*\"law\"     0.006*\"world\"        0.009*\"gadget\"    \n",
       "8       0.008*\"court\"      0.006*\"life\"            0.009*\"pc\"    \n",
       "9     0.007*\"network\"        0.005*\"go\"      0.008*\"consumer\"    \n",
       "10       0.007*\"peer\"       0.005*\"way\"            0.007*\"uk\"    \n",
       "11        0.007*\"new\"       0.005*\"get\"        0.007*\"market\"    \n",
       "12     0.006*\"people\"       0.005*\"old\"         0.007*\"offer\"    \n",
       "13    0.006*\"spyware\"     0.005*\"radio\"            0.006*\"tv\"    \n",
       "14        0.006*\"case\"      0.005*\"good\"           0.006*\"new\"   \n",
       "\n",
       "                    15                 16                       17  \\\n",
       "0        0.034*\"good\"      0.015*\"wales\"            0.013*\"fraud\"    \n",
       "1         0.021*\"win\"    0.014*\"england\"           0.012*\"guilty\"    \n",
       "2       0.017*\"award\"    0.013*\"ireland\"         0.010*\"deutsche\"    \n",
       "3        0.013*\"film\"       0.011*\"half\"              0.010*\"lse\"    \n",
       "4           0.008*\"v\"      0.011*\"rugby\"         0.009*\"exchange\"    \n",
       "5       0.007*\"actor\"     0.009*\"france\"           0.009*\"london\"    \n",
       "6    0.007*\"director\"     0.009*\"minute\"           0.009*\"charge\"    \n",
       "7     0.007*\"british\"        0.008*\"try\"        0.008*\"executive\"    \n",
       "8       0.006*\"prize\"       0.008*\"game\"           0.008*\"boerse\"    \n",
       "9        0.006*\"star\"      0.007*\"squad\"             0.007*\"york\"    \n",
       "10       0.006*\"slam\"     0.007*\"domain\"        0.007*\"radcliffe\"    \n",
       "11   0.006*\"category\"       0.006*\"ukip\"              0.007*\"bid\"    \n",
       "12    0.005*\"actress\"     0.006*\"kilroy\"            0.007*\"plead\"    \n",
       "13        0.005*\"man\"      0.006*\"italy\"    0.006*\"investigation\"    \n",
       "14   0.005*\"favourite\"       0.006*\"ball\"              0.006*\"sec\"   \n",
       "\n",
       "                       18                   19  \n",
       "0            0.014*\"net\"            0.015*\"m\"   \n",
       "1           0.014*\"user\"            0.015*\"£\"   \n",
       "2           0.012*\"mail\"        0.010*\"coach\"   \n",
       "3          0.012*\"virus\"           0.008*\"mr\"   \n",
       "4              0.011*\"e\"            0.006*\"$\"   \n",
       "5           0.011*\"site\"         0.006*\"work\"   \n",
       "6         0.011*\"search\"         0.006*\"week\"   \n",
       "7       0.010*\"software\"          0.005*\"aid\"   \n",
       "8       0.010*\"security\"      0.005*\"pension\"   \n",
       "9         0.009*\"people\"         0.005*\"take\"   \n",
       "10   0.009*\"information\"          0.005*\"pay\"   \n",
       "11      0.008*\"computer\"        0.004*\"woman\"   \n",
       "12        0.008*\"attack\"        0.004*\"union\"   \n",
       "13     0.008*\"microsoft\"    0.004*\"president\"   \n",
       "14        0.008*\"program\"          0.004*\"age\"  "
      ]
     },
     "execution_count": 274,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we retrieve the 15 words with the highest probability to belong to each topic\n",
    "topic_words=lda_model.print_topics(num_words=15)\n",
    "topics=[]\n",
    "for topic in topic_words:\n",
    "    topics.append( topic[1].split('+'))\n",
    "\n",
    "pd.DataFrame(topics).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "omP2koqEJPsU"
   },
   "outputs": [],
   "source": [
    "#We use the model to classify the articles into the topic with highest probability\n",
    "\n",
    "def return_topic(article):\n",
    "    article_bow=dic.doc2bow(article.split())\n",
    "    article_lda = lda_model[article_bow]\n",
    "    article_lda\n",
    "    #sorted sorts the elements of an iterable, in this case the iterable is a list of tuples (topic,probability/frequency) \n",
    "    #we order by frequency\n",
    "    topics_sorted=sorted(article_lda, key=lambda (topic_number, freq): -freq)\n",
    "    #topic with highest probability\n",
    "    return topics_sorted[0][0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tqJB5vtvJPsV"
   },
   "outputs": [],
   "source": [
    "#new column with the topic\n",
    "data['topic']=data.article_lemmatized.map(return_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2u2I9LsJPsV",
    "outputId": "a2600a7e-da71-417e-b171-77637a9d0226"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9     434\n",
       "5     408\n",
       "2     344\n",
       "10    150\n",
       "8     144\n",
       "13    101\n",
       "18     97\n",
       "14     95\n",
       "19     77\n",
       "3      67\n",
       "12     66\n",
       "15     62\n",
       "16     60\n",
       "6      55\n",
       "4      20\n",
       "17     15\n",
       "1      12\n",
       "7      10\n",
       "0       5\n",
       "11      3\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 261,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of articles per topic\n",
    "data.topic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "vXkM1hTLJPsV"
   },
   "outputs": [],
   "source": [
    "# examples of topics that can be found within the general categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8qzhLhYJPsV"
   },
   "source": [
    "1 -> dollar, growth, deficit, economy, rise (business)\n",
    "9 -> $,£, company, bank, firm (business)\n",
    "3 -> mobile, phone (technology)\n",
    "4 -> game, gaming (technology)\n",
    "5 -> government, party, labour, election (politics)\n",
    "18 -> mail, virus, software, security (technology)\n",
    "8 -> film, music, star, award (enterteinment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "N0jZGtucJPsW"
   },
   "outputs": [],
   "source": [
    "# number of articles per topic that belong to each of the general categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fT6m6cUoJPsW",
    "outputId": "8e0ee01b-47ec-4f84-e45a-dcbca8785400"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "topic  category     \n",
       "0      business         4  \n",
       "       entertainment    1  \n",
       "1      business         8  \n",
       "       entertainment    4  \n",
       "2      sport            292\n",
       "       entertainment    34 \n",
       "       business         10 \n",
       "       politics         6  \n",
       "       tech             2  \n",
       "3      tech             54 \n",
       "       business         11 \n",
       "       entertainment    1  \n",
       "       politics         1  \n",
       "4      tech             17 \n",
       "       entertainment    3  \n",
       "5      politics         370\n",
       "       entertainment    14 \n",
       "       business         13 \n",
       "       tech             8  \n",
       "       sport            3  \n",
       "6      tech             37 \n",
       "       entertainment    13 \n",
       "       business         3  \n",
       "       politics         1  \n",
       "       sport            1  \n",
       "7      tech             8  \n",
       "       entertainment    2  \n",
       "8      entertainment    139\n",
       "       tech             3  \n",
       "       business         2  \n",
       "                       ..  \n",
       "11     tech             2  \n",
       "       business         1  \n",
       "12     tech             50 \n",
       "       sport            8  \n",
       "       entertainment    5  \n",
       "       business         3  \n",
       "13     entertainment    68 \n",
       "       tech             26 \n",
       "       politics         4  \n",
       "       business         3  \n",
       "14     tech             80 \n",
       "       business         9  \n",
       "       entertainment    5  \n",
       "       politics         1  \n",
       "15     entertainment    49 \n",
       "       sport            7  \n",
       "       tech             5  \n",
       "       business         1  \n",
       "16     sport            54 \n",
       "       entertainment    3  \n",
       "       tech             3  \n",
       "17     business         11 \n",
       "       entertainment    4  \n",
       "18     tech             94 \n",
       "       business         2  \n",
       "       entertainment    1  \n",
       "19     entertainment    28 \n",
       "       business         26 \n",
       "       politics         22 \n",
       "       sport            1  \n",
       "Name: category, Length: 68, dtype: int64"
      ]
     },
     "execution_count": 436,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('topic').category.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgqdfip3JPsW"
   },
   "source": [
    "Examples of interesting topics broken down by general category. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "44cUlIiUJPsW",
    "outputId": "2697bab9-5a5e-441b-b9f7-e2a230ab7fe4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "tech             94\n",
       "business          2\n",
       "entertainment     1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 268,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cybersecurity (mail, virus, user, site, security)\n",
    "\n",
    "data.groupby('topic').category.value_counts()[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fPORJtu_JPsW",
    "outputId": "0103c4ea-a3f1-4909-e72a-d30be80c9435"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "tech             54\n",
       "business         11\n",
       "entertainment     1\n",
       "politics          1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#telephony (mobile,phone, camera)\n",
    "data.groupby('topic').category.value_counts()[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZbOkastCJPsX",
    "outputId": "0f2432f5-fd1a-42e9-9166-23d686f4cbdf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "tech             17\n",
       "entertainment     3\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 270,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gaming\n",
    "data.groupby('topic').category.value_counts()[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "888_pd5cJPsX",
    "outputId": "b5e3c8f1-de42-4608-a6a3-2eb3cf2d4835"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "business         403\n",
       "politics          12\n",
       "entertainment      9\n",
       "tech               9\n",
       "sport              1\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 271,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#market ($,£, company, bank, firm)\n",
    "\n",
    "data.groupby('topic').category.value_counts()[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPnfiWAeJPsX",
    "outputId": "c584065e-82d2-426b-9699-6ee7dfe6aa81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "business         8\n",
       "entertainment    4\n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 272,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# business (dollar, growth, deficit, economy, rise)\n",
    "\n",
    "data.groupby('topic').category.value_counts()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLJes1WZJPsY",
    "outputId": "3c6aea29-b58b-44b0-cac8-d7d3b55833f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "politics         370\n",
       "entertainment    14 \n",
       "business         13 \n",
       "tech             8  \n",
       "sport            3  \n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 390,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#politics (government, party)\n",
    "data.groupby('topic').category.value_counts()[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o1d0Eg72JPsY",
    "outputId": "da22aa61-e7c2-415c-c7d6-9310f3e2bdb5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "sport            292\n",
       "entertainment    34 \n",
       "business         10 \n",
       "politics         6  \n",
       "tech             2  \n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 391,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sport1 (play, game, team)\n",
    "data.groupby('topic').category.value_counts()[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A1EEyuEAJPsY",
    "outputId": "2e670742-fd5c-4ae9-d395-f99935ac7eeb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "sport            144\n",
       "entertainment    3  \n",
       "tech             3  \n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 392,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sport2 (win, final, champion)\n",
    "data.groupby('topic').category.value_counts()[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cmre7OxTJPsY",
    "outputId": "6c85df23-5371-4340-a1b9-cf12b7f75e93"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "entertainment    139\n",
       "tech             3  \n",
       "business         2  \n",
       "Name: category, dtype: int64"
      ]
     },
     "execution_count": 439,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#entertainment (film, music, star, award)\n",
    "data.groupby('topic').category.value_counts()[8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PiSeW9cKJPsY"
   },
   "source": [
    "We have performed an initial exploration of what could be achieved with LDA. We have found topics within the general categories that can be useful to classify the text at a more granular level. One of the drawbacks of this algorithm is the fact that it needs a post-training human interpreation to interpret the topics. Also the number of topics needs to be defined a priori which is a common problem within the family of clustering algorithms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "54BPyq7EJPsZ",
    "outputId": "7b500735-90c7-4ab4-f49a-756ee5c35ffc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 281,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.system('jupyter nbconvert --to html technical_task_clara_higuera-submission.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "wYzoa9_eJPsZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "technical_task_BTS.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
