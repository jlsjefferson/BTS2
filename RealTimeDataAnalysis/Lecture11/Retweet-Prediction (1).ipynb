{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e411135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark= SparkSession.builder.appName(\"Retweet-Prediction\").getOrCreate()\n",
    "df= spark.read.csv(\"../data/train.data\", sep= '\\t')\n",
    "label= spark.read.csv(\"../data/train.solution\", sep= '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ed34b14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "24b7f99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data:  8151524 , 11\n",
      "Shape of the label:  8151524 , 11\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of the data: \", df.count(), \",\", len(df.columns))\n",
    "print(\"Shape of the label: \", label.count(),  \",\", len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d14afe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "old_cols= df.columns\n",
    "new_cols= [\"Tweet_id\", \"Username\", \"Timestamp\", \"#Followers\",\n",
    "            \"#Friends\", \"#Favorites\", \"Entities\", \"Sentiment\", \"Mentions\",\n",
    "            \"Hashtags\", \"URLs\"]\n",
    "old_label_col= label.columns\n",
    "new_label_col= [\"label\"]\n",
    "\n",
    "df = reduce(lambda df, idx: df.withColumnRenamed(old_cols[idx], new_cols[idx]), range(len(old_cols)), df)\n",
    "label = reduce(lambda label, idx: label.withColumnRenamed(old_label_col[idx], new_label_col[idx]), range(len(old_label_col)), label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f48fba4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()== label.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eff0b810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+\n",
      "|#Followers|#Friends|\n",
      "+----------+--------+\n",
      "|       619|     770|\n",
      "|     36365|   19344|\n",
      "|      5018|    1933|\n",
      "+----------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"#Followers\", \"#Friends\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "964f32a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "df = df.withColumn(\"id\", monotonically_increasing_id())\n",
    "label = label.withColumn(\"id\", monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0b60cd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.join(label, \"id\", \"inner\").drop(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "112a8acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tweet_id',\n",
       " 'Username',\n",
       " 'Timestamp',\n",
       " '#Followers',\n",
       " '#Friends',\n",
       " '#Favorites',\n",
       " 'Entities',\n",
       " 'Sentiment',\n",
       " 'Mentions',\n",
       " 'Hashtags',\n",
       " 'URLs',\n",
       " 'label']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adf790d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-----+\n",
      "|#Followers|#Friends|label|\n",
      "+----------+--------+-----+\n",
      "|        50|      99|    0|\n",
      "|    667486|     372|  153|\n",
      "|       134|    1124|    0|\n",
      "+----------+--------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"#Followers\", \"#Friends\", \"label\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bd4c1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data= df\n",
    "df= df.select(\"#Followers\", \"#Friends\", \"#Favorites\", \"label\")\n",
    "df = df.withColumn(\"#Followers\", df[\"#Followers\"].cast(\"double\"))\n",
    "df = df.withColumn(\"#Friends\", df[\"#Friends\"].cast(\"double\"))\n",
    "df = df.withColumn(\"#Favorites\", df[\"#Favorites\"].cast(\"double\"))\n",
    "df = df.withColumn(\"label\", df[\"label\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0ff3f800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('#Followers', 'double'),\n",
       " ('#Friends', 'double'),\n",
       " ('#Favorites', 'double'),\n",
       " ('label', 'double')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f001b31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+-----+----------------+\n",
      "|#Favorites|#Followers|#Friends|label|      prediction|\n",
      "+----------+----------+--------+-----+----------------+\n",
      "|       0.0|       0.0|     0.0|  0.0|35.9098968748891|\n",
      "|       0.0|       0.0|     0.0|  0.0|35.9098968748891|\n",
      "|       0.0|       0.0|     0.0|  0.0|35.9098968748891|\n",
      "|       0.0|       0.0|     0.0|  0.0|35.9098968748891|\n",
      "|       0.0|       0.0|     0.0|  0.0|35.9098968748891|\n",
      "+----------+----------+--------+-----+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=[\"#Favorites\", \"#Followers\", \"#Friends\"], outputCol=\"features\")\n",
    "lr= LinearRegression()\n",
    "pipeline = Pipeline(stages=[vecAssembler, lr])\n",
    "\n",
    "trainDF, testDF = df.randomSplit([.7, .3], seed=42)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "predDF = pipelineModel.transform(testDF)\n",
    "predDF.select(\"#Favorites\", \"#Followers\", \"#Friends\", \"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7760358e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 is 0.0038296589432468275\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regressionEvaluator= RegressionEvaluator()\n",
    "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
    "print(f\"R2 is {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e6d86617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+-----+------------------+\n",
      "|#Favorites|#Followers|#Friends|label|        prediction|\n",
      "+----------+----------+--------+-----+------------------+\n",
      "|       0.0|       0.0|     0.0|  0.0|33.297817827778815|\n",
      "|       0.0|       0.0|     0.0|  0.0|33.297817827778815|\n",
      "|       0.0|       0.0|     0.0|  0.0|33.297817827778815|\n",
      "|       0.0|       0.0|     0.0|  0.0|33.297817827778815|\n",
      "|       0.0|       0.0|     0.0|  0.0|33.297817827778815|\n",
      "+----------+----------+--------+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "vecAssembler = VectorAssembler(inputCols=[\"#Favorites\", \"#Followers\", \"#Friends\"], outputCol=\"features\")\n",
    "rf= RandomForestRegressor()\n",
    "pipeline = Pipeline(stages=[vecAssembler, rf])\n",
    "\n",
    "trainDF, testDF = df.randomSplit([.7, .3], seed=42)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "predDF = pipelineModel.transform(testDF)\n",
    "predDF.select(\"#Favorites\", \"#Followers\", \"#Friends\", \"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3f276822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 is 0.0019903051652915282\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regressionEvaluator= RegressionEvaluator()\n",
    "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
    "print(f\"R2 is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8b552",
   "metadata": {},
   "source": [
    "## Exploring Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6c48e1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+---------+-----+\n",
      "|#Favorites|#Followers|#Friends|Sentiment|label|\n",
      "+----------+----------+--------+---------+-----+\n",
      "|         0|        50|      99|     2 -1|    0|\n",
      "|       154|    667486|     372|     1 -1|  153|\n",
      "|         0|       134|    1124|     1 -4|    0|\n",
      "+----------+----------+--------+---------+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df= data.select(\"#Favorites\", \"#Followers\", \"#Friends\", \"Sentiment\", \"label\")\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e5100a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import split\n",
    "sentiments= df.select(split(df.Sentiment,\" \")).rdd.flatMap(\n",
    "              lambda x: x).toDF(schema=[\"pos\",\"neg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1145693d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "df = df.withColumn(\"id\", monotonically_increasing_id())\n",
    "sentiments = sentiments.withColumn(\"id\", monotonically_increasing_id())\n",
    "df = df.join(sentiments, \"id\", \"inner\").drop(\"id\")\n",
    "del sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "98ac7a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+--------+---+---+-----+\n",
      "|#Favorites|#Followers|#Friends|pos|neg|label|\n",
      "+----------+----------+--------+---+---+-----+\n",
      "|         0|       107|     255|  1| -1|    0|\n",
      "|         7|      1140|    1122|  3| -1|    1|\n",
      "|         0|        52|     191|  2| -1|    0|\n",
      "+----------+----------+--------+---+---+-----+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"#Favorites\", \"#Followers\", \"#Friends\", \"pos\", \"neg\", \"label\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "249b32ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"#Followers\", df[\"#Followers\"].cast(\"double\"))\n",
    "df = df.withColumn(\"#Friends\", df[\"#Friends\"].cast(\"double\"))\n",
    "df = df.withColumn(\"#Favorites\", df[\"#Favorites\"].cast(\"double\"))\n",
    "df = df.withColumn(\"pos\", df[\"pos\"].cast(\"double\"))\n",
    "df = df.withColumn(\"neg\", df[\"neg\"].cast(\"double\"))\n",
    "df = df.withColumn(\"label\", df[\"label\"].cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "ebb4c724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "\n",
    "vecAssembler = VectorAssembler(\n",
    "    inputCols=[\"#Favorites\", \"#Followers\", \"#Friends\", \"pos\", \"neg\"], \n",
    "    outputCol=\"features\")\n",
    "\n",
    "rf= RandomForestRegressor()\n",
    "pipeline = Pipeline(stages=[vecAssembler, rf])\n",
    "\n",
    "trainDF, testDF = df.randomSplit([.7, .3], seed=42)\n",
    "pipelineModel = pipeline.fit(trainDF)\n",
    "predDF = pipelineModel.transform(testDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d01d14eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 is 0.0025308919993899393\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "regressionEvaluator= RegressionEvaluator()\n",
    "r2 = regressionEvaluator.setMetricName(\"r2\").evaluate(predDF)\n",
    "print(f\"R2 is {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20440332",
   "metadata": {},
   "source": [
    "## Exploring Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f0ba5a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------+\n",
      "|entities                                                                 |\n",
      "+-------------------------------------------------------------------------+\n",
      "|obese:Obesity:-2.3419573228805777;                                       |\n",
      "|hong kong:Hong_Kong:-1.992910022963458;                                  |\n",
      "|xenophobic:Xenophobia:-1.5869752955754004;china:China:-2.113921624336916;|\n",
      "+-------------------------------------------------------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "entities= data.select(\"entities\")\n",
    "entities.show(3, truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "cec56dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|mentions                  |\n",
      "+--------------------------+\n",
      "|carlquintanilla           |\n",
      "|null;                     |\n",
      "|SenSchumer realDonaldTrump|\n",
      "+--------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mentions= data.select(\"mentions\")\n",
    "mentions.show(3, truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4dfc1d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|hashtags              |\n",
      "+----------------------+\n",
      "|null;                 |\n",
      "|LIVE: hongkongprotests|\n",
      "|null;                 |\n",
      "+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hashtags= data.select(\"hashtags\")\n",
    "hashtags.show(3, truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9a7a7a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|URLs                  |\n",
      "+----------------------+\n",
      "|null;                 |\n",
      "|https://sc.mp/ainy1:-:|\n",
      "|null;                 |\n",
      "+----------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "urls= data.select(\"URLs\")\n",
    "urls.show(3, truncate= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fca7fd1",
   "metadata": {},
   "source": [
    "### Addition of Categorical Features\n",
    "\n",
    "1. Perform TF-IDF over the mentions and/ or entities/hastags/URLs with limited vocabulary and observe performance.\n",
    "2. Repeat the process by enhancing the vocabulary and observe changes in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d131809",
   "metadata": {},
   "source": [
    "### Extraction from Existing Features\n",
    "1. Examine if the model behaves better by adding an average sentiment by summing the positive and negative sentiments\n",
    "2. Observe by splitting the timestamp into days, month and year (dropping year if neeeded or performing One-Hot Encoding) if the individual days, month and/or year play some role in improving the model\n",
    "3. Obtain the count of URLs in each tweet (probably, tweets with more links are more likely to get viral)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74149939",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
